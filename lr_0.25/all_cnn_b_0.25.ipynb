{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"all_cnn_b_0.25.ipynb","provenance":[{"file_id":"103BRRDb5y9_dfYGjX0_e1diwM6Oia4uZ","timestamp":1583682814867},{"file_id":"https://github.com/jblok27/DL_RP5/blob/master/ModelB_Experiment.ipynb","timestamp":1583673409198}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c15d98b3471a4e7aa01f49ca0670f52f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a219f2f621a94563ab295017d34816e1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d1232a8091b748b39cd7f6cf5d8f17c0","IPY_MODEL_bbdda0995c114b25b4283cccd9a6f432"]}},"a219f2f621a94563ab295017d34816e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1232a8091b748b39cd7f6cf5d8f17c0":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7846d032127a4e518529cae116ab8184","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1dcdc486f9834308bed23243046d3ac3"}},"bbdda0995c114b25b4283cccd9a6f432":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_379bfc9f2ec049479b0754cdc4d7eee8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:30&lt;00:00, 16096516.05it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4acac420539343e68ef2beb7047d4948"}},"7846d032127a4e518529cae116ab8184":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1dcdc486f9834308bed23243046d3ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"379bfc9f2ec049479b0754cdc4d7eee8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4acac420539343e68ef2beb7047d4948":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"WUDi6QICWB4v","colab_type":"code","outputId":"61bd9775-812a-479b-badb-ecfb472b7f43","executionInfo":{"status":"ok","timestamp":1584802582475,"user_tz":-60,"elapsed":26627,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["cuda = True\n","train_batch_size = 32\n","test_batch_size = 124\n","best_loss = float(\"inf\")\n","best_epoch = -1\n","dataset_path = './cifar10'\n","gsync_save = True\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UL2k5sCqFKJ","colab_type":"code","outputId":"98a8baa5-ba1d-446f-d5ed-2c0f28895482","executionInfo":{"status":"ok","timestamp":1584802582476,"user_tz":-60,"elapsed":8445,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torchsummary import summary\n","\n","class AllConvNet(nn.Module):\n","    def __init__(self, input_size, n_classes=10, **kwargs):\n","        super(AllConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(input_size, 96, 5, padding=1)\n","        self.conv2 = nn.Conv2d(96, 96, 1, padding=1)\n","        self.conv3 = nn.Conv2d(96, 96, 3, padding=1, stride=2) \n","        self.conv4 = nn.Conv2d(96, 192, 5, padding=1) \n","        self.conv5 = nn.Conv2d(192, 192, 1, padding=1) \n","        self.conv6 = nn.Conv2d(192, 192, 3, stride=2, padding=1) \n","        self.conv7 = nn.Conv2d(192, 192, 3, padding=1) \n","        self.conv8 = nn.Conv2d(192, 192, 1)\n","\n","        self.class_conv = nn.Conv2d(192, n_classes, 1)\n","\n","\n","    def forward(self, x):\n","        x_drop = F.dropout(x, .2)\n","        conv1_out = F.relu(self.conv1(x_drop))\n","        conv2_out = F.relu(self.conv2(conv1_out))\n","        conv3_out = F.relu(self.conv3(conv2_out))\n","        conv3_out_drop = F.dropout(conv3_out, .5)\n","        conv4_out = F.relu(self.conv4(conv3_out_drop))\n","        conv5_out = F.relu(self.conv5(conv4_out))\n","        conv6_out = F.relu(self.conv6(conv5_out))\n","        conv6_out_drop = F.dropout(conv6_out, .5)\n","        conv7_out = F.relu(self.conv7(conv6_out_drop))\n","        conv8_out = F.relu(self.conv8(conv7_out))\n","\n","        class_out = F.relu(self.class_conv(conv8_out))\n","        pool_out = F.adaptive_avg_pool2d(class_out, 1)\n","        pool_out.squeeze_(-1)\n","        pool_out.squeeze_(-1)\n","        return pool_out\n","        \n","trial=AllConvNet(3)\n","print(trial)\n","\n","#summary(trial.cuda(),(3,32,32))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["AllConvNet(\n","  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (conv4): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n","  (conv6): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (conv7): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv8): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","  (class_conv): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZu8tSSYvXVL","colab_type":"code","outputId":"cf716b14-84de-4246-c58c-ba671c49f6c2","executionInfo":{"status":"ok","timestamp":1584802599827,"user_tz":-60,"elapsed":17332,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["c15d98b3471a4e7aa01f49ca0670f52f","a219f2f621a94563ab295017d34816e1","d1232a8091b748b39cd7f6cf5d8f17c0","bbdda0995c114b25b4283cccd9a6f432","7846d032127a4e518529cae116ab8184","1dcdc486f9834308bed23243046d3ac3","379bfc9f2ec049479b0754cdc4d7eee8","4acac420539343e68ef2beb7047d4948"]}},"source":["cuda =torch.cuda.is_available()\n","trainset = datasets.CIFAR10(root=dataset_path, train=True, download=True)\n","train_mean = trainset.data.mean(axis=(0,1,2))/255  # [0.49139968  0.48215841  0.44653091]\n","train_std = trainset.data.std(axis=(0,1,2))/255  # [0.24703223  0.24348513  0.26158784]\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(train_mean, train_std),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(train_mean, train_std),\n","])\n","kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n","train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\n","    root=dataset_path, train=True, download=True,\n","    transform=transform_train),\n","    batch_size=train_batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10(root=dataset_path, train=False, download=True,\n","    transform=transform_test),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c15d98b3471a4e7aa01f49ca0670f52f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3WISJzjRvXVP","colab_type":"code","colab":{}},"source":["model = AllConvNet(3)\n","if cuda:\n","    model.cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.25, momentum=0.9, weight_decay=0.001)\n","scheduler = optim.lr_scheduler.MultiStepLR(\n","    optimizer, milestones=[200, 250, 300], gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5shX88fvvXVR","colab_type":"code","colab":{}},"source":["def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if cuda:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","            \n","def test(epoch, best_loss, best_epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        if cuda:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","\n","        output = model(data)\n","        # sum up batch loss\n","        test_loss += criterion(output, target).data.item()\n","        # get the index of the max log-probability\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print(\n","        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","            test_loss, correct, len(test_loader.dataset), 100. * correct /\n","            len(test_loader.dataset)))\n","    \n","    if test_loss < best_loss:\n","        best_epoch = epoch\n","        best_loss = test_loss\n","        torch.save(model, \"best.pt\")\n","        # if gsync_save:\n","        #     gsync.update_file_to_folder(\"best.pt\")\n","    return best_loss, best_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_YHklUQvXVU","colab_type":"code","outputId":"c9ba51ab-f29b-4a9d-b4d1-ea906c85bed3","executionInfo":{"status":"ok","timestamp":1584472822140,"user_tz":-60,"elapsed":8201961,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch in range(350):\n","    train(epoch)\n","    scheduler.step()\n","    best_loss, best_epoch = test(epoch, best_loss, best_epoch)\n","\n","model_save_name = 'all_cnn_b_0_25.pth'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\"\n","torch.save(model.state_dict(), path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.302353\n","Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.301021\n","Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.301409\n","Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.294218\n","Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.296011\n","Train Epoch: 0 [16000/50000 (32%)]\tLoss: 2.302618\n","Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 0 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 0 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 0 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 0 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 0 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 0 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 0 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 0 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type AllConvNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 1 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 1 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 1 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 1 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 2 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 2 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 2 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 2 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 2 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 2 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 2 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 3 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 3 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 3 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 3 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 3 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 3 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 3 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 3 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 3 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 3 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 3 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 3 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 4 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 4 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 4 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 4 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 4 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 4 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 4 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 4 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 4 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 4 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 4 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 5 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 5 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 5 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 5 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 5 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 5 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 5 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 5 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 5 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 5 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 5 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 5 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1001/10000 (10%)\n","\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 6 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 6 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 6 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 6 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 6 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 6 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 6 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 6 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 6 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 6 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 6 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 6 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 7 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 7 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 7 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 7 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 7 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 7 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 7 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 7 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 7 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 7 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 7 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 7 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 8 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 8 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 8 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 8 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 8 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 8 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 8 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 8 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 8 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 8 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 8 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 8 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 8 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 9 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 9 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 9 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 9 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 9 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 9 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 9 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 9 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 9 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 9 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 9 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 9 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 9 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 9 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 9 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 10 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 10 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 10 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 10 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 10 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 10 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 10 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 10 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 10 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 10 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 10 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 10 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 10 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 10 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 10 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 11 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 11 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 11 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 11 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 11 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 11 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 11 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 11 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 11 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 11 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 11 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 11 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 11 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 11 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 11 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 11 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 12 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 12 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 12 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 12 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 12 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 12 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 12 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 12 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 12 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 12 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 12 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 12 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 12 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 12 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 12 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 12 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 13 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 13 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 13 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 13 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 13 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 13 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 13 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 13 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 13 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 13 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 13 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 13 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 13 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 13 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 13 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 13 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1001/10000 (10%)\n","\n","Train Epoch: 14 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 14 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 14 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 14 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 14 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 14 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 14 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 14 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 14 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 14 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 14 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 14 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 14 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 14 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 14 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 14 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 15 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 15 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 15 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 15 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 15 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 15 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 15 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 15 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 15 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 15 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 15 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 15 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 15 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 15 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 15 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 15 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 16 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 16 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 16 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 16 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 16 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 16 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 16 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 16 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 16 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 16 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 16 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 16 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 16 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 16 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 16 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 16 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 17 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 17 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 17 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 17 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 17 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 17 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 17 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 17 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 17 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 17 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 17 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 17 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 17 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 17 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 17 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 17 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 18 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 18 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 18 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 18 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 18 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 18 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 18 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 18 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 18 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 18 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 18 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 18 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 18 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 18 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 18 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 18 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 19 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 19 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 19 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 19 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 19 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 19 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 19 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 19 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 19 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 19 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 19 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 19 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 19 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 19 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 19 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 19 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 20 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 20 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 20 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 20 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 20 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 20 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 20 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 20 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 20 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 20 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 20 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 20 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 20 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 20 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 20 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 20 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 21 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 21 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 21 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 21 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 21 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 21 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 21 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 21 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 21 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 21 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 21 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 21 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 21 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 21 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 21 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 21 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 22 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 22 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 22 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 22 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 22 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 22 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 22 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 22 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 22 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 22 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 22 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 22 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 22 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 22 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 22 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 22 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 23 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 23 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 23 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 23 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 23 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 23 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 23 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 23 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 23 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 23 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 23 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 23 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 23 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 23 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 23 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 23 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 24 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 24 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 24 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 24 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 24 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 24 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 24 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 24 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 24 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 24 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 24 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 24 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 24 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 24 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 24 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 24 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 25 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 25 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 25 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 25 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 25 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 25 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 25 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 25 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 25 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 25 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 25 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 25 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 25 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 25 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 25 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 25 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 26 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 26 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 26 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 26 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 26 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 26 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 26 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 26 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 26 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 26 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 26 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 26 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 26 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 26 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 26 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 26 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 27 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 27 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 27 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 27 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 27 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 27 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 27 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 27 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 27 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 27 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 27 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 27 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 27 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 27 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 27 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 27 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 28 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 28 [3200/50000 (6%)]\tLoss: 2.302585\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1-9ksOb8ykHx","colab_type":"code","colab":{}},"source":["# if in Google Colab, download your model with this\n","# from google.colab import files\n","# files.download(\"best.pt\")"],"execution_count":0,"outputs":[]}]}