{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"all_cnn_b_0.001.ipynb","provenance":[{"file_id":"103BRRDb5y9_dfYGjX0_e1diwM6Oia4uZ","timestamp":1583682814867},{"file_id":"https://github.com/jblok27/DL_RP5/blob/master/ModelB_Experiment.ipynb","timestamp":1583673409198}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"60ac0faaac584c5597bccd28be26fd84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b30d3b19517246e0ae90fb5a9e515029","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4872a1a37b9140aa956519fed3cee5f2","IPY_MODEL_035415b004c142769418c57694e76e14"]}},"b30d3b19517246e0ae90fb5a9e515029":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4872a1a37b9140aa956519fed3cee5f2":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e7f3e1b85d7f4506b140de3cb3b4767d","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a9b7f9248e843cc8ee7c7d5d7887fcb"}},"035415b004c142769418c57694e76e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ef6022557f14aa88bf0acafa4173732","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:30&lt;00:00, 14803485.50it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9886dc30d0e4a179c26276c74419613"}},"e7f3e1b85d7f4506b140de3cb3b4767d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0a9b7f9248e843cc8ee7c7d5d7887fcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ef6022557f14aa88bf0acafa4173732":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9886dc30d0e4a179c26276c74419613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"6Aec3t1XV_-9","colab_type":"code","colab":{}},"source":["# if gsync_save:\n","#     try:\n","#         import utils\n","#     except ModuleNotFoundError:\n","#         !wget https://raw.githubusercontent.com/StefOe/colab-pytorch-utils/HEAD/utils.py\n","#         import utils\n","\n","#     gsync = utils.GDriveSync()\n","# try:\n","#     from allconv import AllConvNet\n","# except ModuleNotFoundError: \n","#     !wget https://github.com/StefOe/all-conv-pytorch/raw/HEAD/allconv.py\n","#     from allconv import AllConvNet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUDi6QICWB4v","colab_type":"code","outputId":"369fa0bd-2179-4f27-9229-0a66175bf014","executionInfo":{"status":"ok","timestamp":1585133840561,"user_tz":-60,"elapsed":37556,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["cuda = True\n","train_batch_size = 32\n","test_batch_size = 124\n","best_loss = float(\"inf\")\n","best_epoch = -1\n","dataset_path = './cifar10'\n","gsync_save = True\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UL2k5sCqFKJ","colab_type":"code","outputId":"f7b89b08-d1b3-4bde-946e-ea6720e0e802","executionInfo":{"status":"ok","timestamp":1585133840568,"user_tz":-60,"elapsed":37548,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torchsummary import summary\n","\n","class AllConvNet(nn.Module):\n","    def __init__(self, input_size, n_classes=10, **kwargs):\n","        super(AllConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(input_size, 96, 5, padding=1)\n","        self.conv2 = nn.Conv2d(96, 96, 1, padding=1)\n","        self.conv3 = nn.Conv2d(96, 96, 3, padding=1, stride=2)\n","        self.conv4 = nn.Conv2d(96, 192, 5, padding=1)\n","        self.conv5 = nn.Conv2d(192, 192, 1, padding=1)\n","        self.conv6 = nn.Conv2d(192, 192, 3, stride=2, padding=1)\n","        self.conv7 = nn.Conv2d(192, 192, 3, padding=1)\n","        self.conv8 = nn.Conv2d(192, 192, 1)\n","\n","        self.class_conv = nn.Conv2d(192, n_classes, 1)\n","\n","\n","    def forward(self, x):\n","        x_drop = F.dropout(x, .2)\n","        conv1_out = F.relu(self.conv1(x_drop))\n","        conv2_out = F.relu(self.conv2(conv1_out))\n","        conv3_out = F.relu(self.conv3(conv2_out))\n","        conv3_out_drop = F.dropout(conv3_out, .5)\n","        conv4_out = F.relu(self.conv4(conv3_out_drop))\n","        conv5_out = F.relu(self.conv5(conv4_out))\n","        conv6_out = F.relu(self.conv6(conv5_out))\n","        conv6_out_drop = F.dropout(conv6_out, .5)\n","        conv7_out = F.relu(self.conv7(conv6_out_drop))\n","        conv8_out = F.relu(self.conv8(conv7_out))\n","\n","        class_out = F.relu(self.class_conv(conv8_out))\n","        pool_out = F.adaptive_avg_pool2d(class_out, 1)\n","        pool_out.squeeze_(-1)\n","        pool_out.squeeze_(-1)\n","        return pool_out\n","        \n","trial=AllConvNet(3)\n","print(trial)\n","\n","#summary(trial.cuda(),(3,32,32))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["AllConvNet(\n","  (conv1): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (conv4): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n","  (conv6): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","  (conv7): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv8): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","  (class_conv): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rZu8tSSYvXVL","colab_type":"code","outputId":"b5c35ab6-a884-4133-9816-b77f0e0f2e78","executionInfo":{"status":"ok","timestamp":1585133858912,"user_tz":-60,"elapsed":55881,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["60ac0faaac584c5597bccd28be26fd84","b30d3b19517246e0ae90fb5a9e515029","4872a1a37b9140aa956519fed3cee5f2","035415b004c142769418c57694e76e14","e7f3e1b85d7f4506b140de3cb3b4767d","0a9b7f9248e843cc8ee7c7d5d7887fcb","2ef6022557f14aa88bf0acafa4173732","e9886dc30d0e4a179c26276c74419613"]}},"source":["cuda =torch.cuda.is_available()\n","trainset = datasets.CIFAR10(root=dataset_path, train=True, download=True)\n","#train_mean = trainset.train_data.mean(axis=(0,1,2))/255  # [0.49139968  0.48215841  0.44653091]\n","#train_std = trainset.train_data.std(axis=(0,1,2))/255  # [0.24703223  0.24348513  0.26158784]\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    #transforms.Normalize(train_mean, train_std),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    #transforms.Normalize(train_mean, train_std),\n","])\n","kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n","train_loader = torch.utils.data.DataLoader(datasets.CIFAR10(\n","    root=dataset_path, train=True, download=True,\n","    transform=transform_train),\n","    batch_size=train_batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.CIFAR10(root=dataset_path, train=False, download=True,\n","    transform=transform_test),\n","    batch_size=test_batch_size, shuffle=False, **kwargs)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60ac0faaac584c5597bccd28be26fd84","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3WISJzjRvXVP","colab_type":"code","colab":{}},"source":["model = AllConvNet(3)\n","if cuda:\n","    model.cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n","scheduler = optim.lr_scheduler.MultiStepLR(\n","    optimizer, milestones=[200, 250, 300], gamma=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5shX88fvvXVR","colab_type":"code","colab":{}},"source":["def train(epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        if cuda:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","            \n","def test(epoch, best_loss, best_epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for data, target in test_loader:\n","        if cuda:\n","            data, target = data.cuda(), target.cuda()\n","        data, target = Variable(data), Variable(target)\n","\n","        output = model(data)\n","        # sum up batch loss\n","        test_loss += criterion(output, target).data.item()\n","        # get the index of the max log-probability\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print(\n","        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","            test_loss, correct, len(test_loader.dataset), 100. * correct /\n","            len(test_loader.dataset)))\n","    \n","    if test_loss < best_loss:\n","        best_epoch = epoch\n","        best_loss = test_loss\n","        model_save_name = 'all_cnn_b_0_001.pth'\n","        path = F\"/content/gdrive/My Drive/{model_save_name}\"\n","        torch.save(model.state_dict(), path)\n","        print(\"new best\")\n","        print(best_epoch)\n","        #torch.save(model, \"best.pt\")\n","        # if gsync_save:\n","        #     gsync.update_file_to_folder(\"best.pt\")\n","    return best_loss, best_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_YHklUQvXVU","colab_type":"code","outputId":"df2f407c-72cd-4d52-9794-7d693df89fee","executionInfo":{"status":"ok","timestamp":1584472822140,"user_tz":-60,"elapsed":8201961,"user":{"displayName":"Jaap Blok","photoUrl":"","userId":"10428959571041432348"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for epoch in range(350):\n","    train(epoch)\n","    scheduler.step()\n","    best_loss, best_epoch = test(epoch, best_loss, best_epoch)\n","\n","#model_save_name = 'all_cnn_b_0_001.pth'\n","#path = F\"/content/gdrive/My Drive/{model_save_name}\"\n","#torch.save(model.state_dict(), path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.303799\n","Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.312340\n","Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.309432\n","Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.299294\n","Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.300647\n","Train Epoch: 0 [16000/50000 (32%)]\tLoss: 2.300707\n","Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.304370\n","Train Epoch: 0 [22400/50000 (45%)]\tLoss: 2.304113\n","Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.302177\n","Train Epoch: 0 [28800/50000 (58%)]\tLoss: 2.301597\n","Train Epoch: 0 [32000/50000 (64%)]\tLoss: 2.303782\n","Train Epoch: 0 [35200/50000 (70%)]\tLoss: 2.301291\n","Train Epoch: 0 [38400/50000 (77%)]\tLoss: 2.302400\n","Train Epoch: 0 [41600/50000 (83%)]\tLoss: 2.304291\n","Train Epoch: 0 [44800/50000 (90%)]\tLoss: 2.304095\n","Train Epoch: 0 [48000/50000 (96%)]\tLoss: 2.302894\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","new best\n","0\n","Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301612\n","Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.305154\n","Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.304992\n","Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.301146\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.300189\n","Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.302501\n","Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.300657\n","Train Epoch: 1 [22400/50000 (45%)]\tLoss: 2.299307\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.304227\n","Train Epoch: 1 [28800/50000 (58%)]\tLoss: 2.301797\n","Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.302740\n","Train Epoch: 1 [35200/50000 (70%)]\tLoss: 2.301256\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.303819\n","Train Epoch: 1 [41600/50000 (83%)]\tLoss: 2.302351\n","Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.301206\n","Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.302662\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","new best\n","1\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.302409\n","Train Epoch: 2 [3200/50000 (6%)]\tLoss: 2.302711\n","Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.302369\n","Train Epoch: 2 [9600/50000 (19%)]\tLoss: 2.302796\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.302572\n","Train Epoch: 2 [16000/50000 (32%)]\tLoss: 2.302575\n","Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.302535\n","Train Epoch: 2 [22400/50000 (45%)]\tLoss: 2.302897\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.302833\n","Train Epoch: 2 [28800/50000 (58%)]\tLoss: 2.302587\n","Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.302582\n","Train Epoch: 2 [35200/50000 (70%)]\tLoss: 2.302591\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.302587\n","Train Epoch: 2 [41600/50000 (83%)]\tLoss: 2.302586\n","Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.302584\n","Train Epoch: 2 [48000/50000 (96%)]\tLoss: 2.302586\n","\n","Test set: Average loss: 0.0187, Accuracy: 1074/10000 (11%)\n","\n","new best\n","2\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 3 [3200/50000 (6%)]\tLoss: 2.302587\n","Train Epoch: 3 [6400/50000 (13%)]\tLoss: 2.302583\n","Train Epoch: 3 [9600/50000 (19%)]\tLoss: 2.302601\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 2.302588\n","Train Epoch: 3 [16000/50000 (32%)]\tLoss: 2.302587\n","Train Epoch: 3 [19200/50000 (38%)]\tLoss: 2.302587\n","Train Epoch: 3 [22400/50000 (45%)]\tLoss: 2.302587\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 2.302551\n","Train Epoch: 3 [28800/50000 (58%)]\tLoss: 2.302586\n","Train Epoch: 3 [32000/50000 (64%)]\tLoss: 2.302583\n","Train Epoch: 3 [35200/50000 (70%)]\tLoss: 2.302566\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 2.302588\n","Train Epoch: 3 [41600/50000 (83%)]\tLoss: 2.302592\n","Train Epoch: 3 [44800/50000 (90%)]\tLoss: 2.302581\n","Train Epoch: 3 [48000/50000 (96%)]\tLoss: 2.302587\n","\n","Test set: Average loss: 0.0187, Accuracy: 1002/10000 (10%)\n","\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.302584\n","Train Epoch: 4 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 4 [6400/50000 (13%)]\tLoss: 2.302586\n","Train Epoch: 4 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 2.302583\n","Train Epoch: 4 [16000/50000 (32%)]\tLoss: 2.302588\n","Train Epoch: 4 [19200/50000 (38%)]\tLoss: 2.302584\n","Train Epoch: 4 [22400/50000 (45%)]\tLoss: 2.302587\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 2.302579\n","Train Epoch: 4 [28800/50000 (58%)]\tLoss: 2.302583\n","Train Epoch: 4 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 4 [35200/50000 (70%)]\tLoss: 2.302584\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 4 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 4 [44800/50000 (90%)]\tLoss: 2.302587\n","Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1003/10000 (10%)\n","\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 2.302586\n","Train Epoch: 5 [3200/50000 (6%)]\tLoss: 2.302589\n","Train Epoch: 5 [6400/50000 (13%)]\tLoss: 2.302587\n","Train Epoch: 5 [9600/50000 (19%)]\tLoss: 2.302599\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 2.302584\n","Train Epoch: 5 [16000/50000 (32%)]\tLoss: 2.302582\n","Train Epoch: 5 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 5 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 5 [28800/50000 (58%)]\tLoss: 2.302583\n","Train Epoch: 5 [32000/50000 (64%)]\tLoss: 2.302584\n","Train Epoch: 5 [35200/50000 (70%)]\tLoss: 2.302586\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 5 [41600/50000 (83%)]\tLoss: 2.302572\n","Train Epoch: 5 [44800/50000 (90%)]\tLoss: 2.302672\n","Train Epoch: 5 [48000/50000 (96%)]\tLoss: 2.302663\n","\n","Test set: Average loss: 0.0187, Accuracy: 1000/10000 (10%)\n","\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.302706\n","Train Epoch: 6 [3200/50000 (6%)]\tLoss: 2.303467\n","Train Epoch: 6 [6400/50000 (13%)]\tLoss: 2.301672\n","Train Epoch: 6 [9600/50000 (19%)]\tLoss: 2.302630\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 2.301960\n","Train Epoch: 6 [16000/50000 (32%)]\tLoss: 2.302584\n","Train Epoch: 6 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 6 [22400/50000 (45%)]\tLoss: 2.302586\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 2.302586\n","Train Epoch: 6 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 6 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 6 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 6 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 6 [44800/50000 (90%)]\tLoss: 2.302585\n","Train Epoch: 6 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1011/10000 (10%)\n","\n","new best\n","6\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 7 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 7 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 7 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 2.302585\n","Train Epoch: 7 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 7 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 7 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 7 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 7 [32000/50000 (64%)]\tLoss: 2.302585\n","Train Epoch: 7 [35200/50000 (70%)]\tLoss: 2.302585\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 2.302585\n","Train Epoch: 7 [41600/50000 (83%)]\tLoss: 2.302585\n","Train Epoch: 7 [44800/50000 (90%)]\tLoss: 2.302584\n","Train Epoch: 7 [48000/50000 (96%)]\tLoss: 2.302585\n","\n","Test set: Average loss: 0.0187, Accuracy: 1012/10000 (10%)\n","\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 2.302585\n","Train Epoch: 8 [3200/50000 (6%)]\tLoss: 2.302585\n","Train Epoch: 8 [6400/50000 (13%)]\tLoss: 2.302585\n","Train Epoch: 8 [9600/50000 (19%)]\tLoss: 2.302585\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 2.302586\n","Train Epoch: 8 [16000/50000 (32%)]\tLoss: 2.302585\n","Train Epoch: 8 [19200/50000 (38%)]\tLoss: 2.302585\n","Train Epoch: 8 [22400/50000 (45%)]\tLoss: 2.302585\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 2.302585\n","Train Epoch: 8 [28800/50000 (58%)]\tLoss: 2.302585\n","Train Epoch: 8 [32000/50000 (64%)]\tLoss: 2.302584\n","Train Epoch: 8 [35200/50000 (70%)]\tLoss: 2.302585\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1-9ksOb8ykHx","colab_type":"code","colab":{}},"source":["# if in Google Colab, download your model with this\n","# from google.colab import files\n","# files.download(\"best.pt\")"],"execution_count":0,"outputs":[]}]}